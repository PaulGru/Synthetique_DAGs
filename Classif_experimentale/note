cd Classif_experimentale
source .venv/bin/activate

python main.py 
  --dataset synthetic_semi_anti_causal 
  --n 200000 
  --val_frac 0.1 
  
  --ps_train 0.1 0.2 
  --p_test_ood 0.9 
  --label_flip 0.25 
  
  --erm_steps 5000 
  --erm_lr 1e-4 
  
  --irm_steps 5000 
  --irm_lr 1e-4 
  --irm_lambda 750.0 
  
  --eirm_steps 50 
  --eirm_lr 1e-4 
  --eirm_lambda 10.0 
  
  --model_kind mlp
  --eval_every 5 
  --device auto


[ERM] step 5000 | loss=0.3397 | Train(ID): acc=0.850 | Val(ID): acc=0.845 | Test(OOD): acc=0.100
[IRM] step 5000 | loss=0.5730 | Train(ID): acc=0.713 | Val(ID): acc=0.931 | Test(OOD): acc=0.938


python main.py 
  --dataset synthetic_confounding 
  --n 200000 
  --n_test 10000 
  --val_frac 0.1 
  
  --conf_a_train 0.1 0.2 
  --conf_a_test 0.9 
  --conf_w 1.5 
  --conf_label_flip 0.25 
  
  --erm_steps 5000 
  --erm_lr 5e-4 
  
  --irm_steps 5000 
  --irm_lr 5e-4 
  --irm_lambda 750.0 
  
  --model_kind logreg 
  --eval_every 10
  --device auto


[ERM] step 5000 | loss=0.3820 | Train(ID): acc=0.845 | Val(ID): acc=0.679 | Test(OOD): acc=0.315
[IRM] step 5000 | loss=0.5669 | Train(ID): acc=0.710 | Val(ID): acc=0.950 | Test(OOD): acc=0.970


python main.py 
  --dataset synthetic_selection 
  --n 200000 
  --n_test 10000 
  --val_frac 0.1 
  
  --sel_alpha_train 7.0 5.0 
  --sel_alpha_test 6.0 
  --sel_w 1.0 
  --sel_label_flip 0.25 
  
  --erm_steps 2000 
  --erm_lr 2.5e-4 
  
  --irm_steps 2000 
  --irm_lr 2.5e-4 
  --irm_lambda 750 
  
  --model_kind logreg 
  --eval_every 10 
  --device auto


[ERM] step 5000 | loss=0.4976 | Train(ID): acc=0.773 | Val(ID): acc=0.928 | Test(OOD): acc=0.925
[IRM] step 5000 | loss=0.4880 | Train(ID): acc=0.762 | Val(ID): acc=0.877 | Test(OOD): acc=0.873
[EIRM] step 5000 | train-acc=0.767 loss=0.4935 | val-acc=0.907 loss=0.3082 | test-acc=0.907 loss=0.3119